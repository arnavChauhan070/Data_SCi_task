{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83e72eb-2357-4251-b4b8-c0e0c3882122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Logistic Regression =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       105\n",
      "           1       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "===== KNN (k=5) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       105\n",
      "           1       0.75      0.73      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "===== Decision Tree (max_depth=4) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       105\n",
      "           1       0.80      0.69      0.74        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.78      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scenario Question: Predicting Titanic Survival\n",
    "# Researchers are studying the Titanic disaster and want to build models that predict whether a\n",
    "#  passenger would survive or not survive based on their information.\n",
    "# - Features used:\n",
    "# - Passenger class (pclass)\n",
    "# - Gender (sex)\n",
    "# - Age (age)\n",
    "# - Number of siblings/spouses aboard (sibsp)\n",
    "# - Number of parents/children aboard (parch)\n",
    "# - Ticket fare (fare)\n",
    "# - Label:\n",
    "# - 1 = Survived\n",
    "# - 0 = Died\n",
    "# The researchers train three different models:\n",
    "# - Logistic Regression\n",
    "# - K-Nearest Neighbors (KNN) with k=5\n",
    "# - Decision Tree with max depth = 4\n",
    "# They then evaluate each model using a classification report (precision, recall, F1-score, accuracy).\n",
    "# Questions for Learners\n",
    "# - Which model performs best at predicting survival, and why?\n",
    "# - How does Logistic Regression differ from Decision Tree in terms of interpretability?\n",
    "# # - Why is scaling applied before training Logistic Regression and KNN, but not strictly needed\n",
    "#  for Decision Trees?\n",
    "# - Looking at the classification report, what do precision and recall mean in the context of survival\n",
    "#  predictions?\n",
    "# - Precision → Of those predicted to survive, how many actually survived?\n",
    "# - Recall → Of all who truly survived, how many were correctly predicted?\n",
    "# - If you were a historian, which model would you trust more to explain survival patterns, and why?\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'survived']]\n",
    "\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['fare'] = df['fare'].fillna(df['fare'].median())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classification_report(y_test, log_model.predict(X_test_scaled)))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classification_report(y_test, knn.predict(X_test_scaled)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e202b5-38e3-4a1d-93b9-1fe21bcb66c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
